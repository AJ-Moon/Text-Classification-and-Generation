# Text Classification x Text Generation


## ðŸ“˜ Part 1: CLIP â€” Contrastive Languageâ€“Image Pretraining

### ðŸ§  Concept

Implements a simplified version of CLIP (by OpenAI) to connect images and natural language through a shared embedding space. It uses the Flickr8k dataset for training.

### ðŸ”§ Key Components

* **Config Class:** Hyperparameters and model settings
* **CLIPDataset:** Loads images and captions; tokenizes text using DistilBERT
* **Encoders:**

  * Image encoder: ResNet50 (via `timm`)
  * Text encoder: DistilBERT (via Huggingface)
* **Training Objective:** Align image and text embeddings

### ðŸ“¦ Dataset

* **Flickr8k Dataset** from Kaggle: [Link](https://www.kaggle.com/datasets/adityajn105/flickr8k)

### ðŸ“š Libraries

* PyTorch, Transformers, Torchvision, Timm, PIL, Pandas, Matplotlib, tqdm

---

## ðŸ¤– Part 2: Transformers â€” Movie Script Language Model

### ðŸŽ¬ Theme

A storytelling-themed implementation based on the Transformers franchise. Focuses on building a Transformer-based language model from scratch.

### ðŸ§  Architecture

* Encoder-Decoder (Vaswani et al. â€” "Attention Is All You Need")
* No recurrence; uses self-attention + positional encoding

### ðŸ”§ Key Modules

* **TokenizedDataset:** Tokenizes and batches the movie script
* **Configuration:** Defines embedding dimensions, heads, blocks, etc.
* **Multi-Head Attention:** Causal self-attention for text generation
* **Feedforward Network:** GELU-activated MLP
* **Block:** Attention + FFN + LayerNorm
* **TransformerLM:** Complete stack for training/generation

### ðŸ§ª Task

* Train on a *Transformers* movie script to generate character-style text

### ðŸ“š Libraries

* PyTorch, `datasets`, `tiktoken`, `nltk`, numpy, matplotlib

---

## ðŸ“¦ How to Run

1. Download the datasets (Flickr8k and movie script)
2. Open each notebook
3. Follow the cells from top to bottom â€” all key functions and classes are defined within

---


> "Transformers donâ€™t just change languageâ€”they change the world of AI."
